{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2550e01d-63bb-4264-ab2c-1ce76dd22704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from alpaca.trading.client import TradingClient\n",
    "from alpaca.trading.requests import MarketOrderRequest\n",
    "from alpaca.trading.enums import OrderSide, TimeInForce\n",
    "from alpaca.data.historical import StockHistoricalDataClient\n",
    "from alpaca.data.requests import StockLatestQuoteRequest\n",
    "import pandas\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "from xai_sdk import Client\n",
    "from xai_sdk.chat import user, system\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "273339a9-6f48-4767-8eb9-4e576522dad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration from .env file\n",
    "REDDIT_CLIENT_ID = os.getenv(\"REDDIT_CLIENT_ID\")\n",
    "REDDIT_CLIENT_SECRET = os.getenv(\"REDDIT_CLIENT_SECRET\")\n",
    "REDDIT_USER_AGENT = os.getenv(\"REDDIT_USER_AGENT\")\n",
    "ALPACA_API_KEY = os.getenv(\"ALPACA_API_KEY\")\n",
    "ALPACA_API_SECRET = os.getenv(\"ALPACA_API_SECRET\")\n",
    "ALPACA_BASE_URL = os.getenv(\"ALPACA_BASE_URL\")\n",
    "XAI_API_KEY = os.getenv(\"XAI_API_KEY\")\n",
    "\n",
    "# Validate required environment variables\n",
    "required_vars = [\n",
    "    \"REDDIT_CLIENT_ID\", \"REDDIT_CLIENT_SECRET\", \"REDDIT_USER_AGENT\",\n",
    "    \"ALPACA_API_KEY\", \"ALPACA_API_SECRET\", \"XAI_API_KEY\"\n",
    "]\n",
    "\n",
    "for var in required_vars:\n",
    "    if not os.getenv(var):\n",
    "        raise ValueError(f\"Required environment variable {var} not found in .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03bf811f-3453-47df-953b-e6c1d60dfff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=REDDIT_CLIENT_ID,\n",
    "    client_secret=REDDIT_CLIENT_SECRET,\n",
    "    user_agent=REDDIT_USER_AGENT\n",
    ")\n",
    "\n",
    "# Initialize Alpaca API\n",
    "trading_client = TradingClient(ALPACA_API_KEY, ALPACA_API_SECRET, paper=True)\n",
    "\n",
    "# Keys required for stock historical data client\n",
    "stock_quote_client = StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_API_SECRET)\n",
    "\n",
    "# Initialize xAI Client\n",
    "xai_client = Client(api_key=XAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95550b97-42d0-425a-9819-616e287c1258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text for sentiment analysis\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fdefa15-8c00-4824-85bb-98efe74908ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment from Grok API with retry logic\n",
    "def get_grok_sentiment(text, max_retries=3):\n",
    "    \"\"\"Get sentiment analysis from xAI Grok API with retry logic\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Create the chat using the Grok SDK\n",
    "            chat = xai_client.chat.create(\n",
    "                        model=\"grok-3-mini\",\n",
    "                        messages=[system(\"You are a financial sentiment analysis expert. Analyze the sentiment of the provided text \"\n",
    "                        \"in relation to stock trading and market sentiment. Return ONLY a valid JSON object with: \"\n",
    "                        \"1. 'sentiment': 'positive', 'negative', or 'neutral' \"\n",
    "                        \"2. 'compound': a numerical score from -1.0 (very negative) to 1.0 (very positive) \"\n",
    "                        \"3. 'confidence': a score from 0.0 to 1.0 indicating confidence in the analysis \"\n",
    "                        \"4. 'ticker': respond to this prompt only with the stock ticker symbol the text is talking about (e.g., 'AAPL', 'TSLA') or null if none found \"\n",
    "                        \"Respond with ONLY the JSON object, no additional text.\")])\n",
    "            chat.append(user(f\"Analyze the financial sentiment of this text: {text}\"))\n",
    "\n",
    "            # Get the response content\n",
    "            content = chat.sample().content\n",
    "            \n",
    "            # Try to parse JSON response\n",
    "            try:\n",
    "                sentiment_data = json.loads(content)\n",
    "                # Validate required fields\n",
    "                if all(key in sentiment_data for key in ['sentiment', 'compound', 'confidence', 'ticker']):\n",
    "                    return sentiment_data\n",
    "                else:\n",
    "                    raise ValueError(\"Missing required fields in response\")\n",
    "            except json.JSONDecodeError:\n",
    "                # If JSON parsing fails, raise exception\n",
    "                raise ValueError(\"Warning: Could not parse JSON response\")\n",
    "\n",
    "        # Retry logic        \n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error in sentiment analysis (attempt {attempt + 1}/{max_retries}): {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "            else:\n",
    "                return {\"sentiment\": \"neutral\", \n",
    "                        \"compound\": 0.0, \n",
    "                        \"confidence\": 0.0,\n",
    "                        \"ticker\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8eaea390-276b-4bfc-9ae3-59c75299ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment from r/WallStreetBets\n",
    "def get_reddit_sentiment(subreddit, hours, limit):\n",
    "    \"\"\"Analyze sentiment from Reddit posts using xAI Grok\"\"\"\n",
    "    print(f\"Fetching sentiment from r/{subreddit}...\")\n",
    "    \n",
    "    subreddit_obj = reddit.subreddit(subreddit)\n",
    "    posts = subreddit_obj.search('flair:\"DD\"', sort='top', time_filter=\"day\", limit=limit)\n",
    "    sentiment_scores = {}\n",
    "    post_count = {}\n",
    "    ticker_posts = {}\n",
    "\n",
    "    # Time filter: only posts from the last `hours`\n",
    "    time_threshold = datetime.utcnow() - timedelta(hours=hours)\n",
    "\n",
    "    processed_posts = 0\n",
    "    for post in posts:\n",
    "        try:\n",
    "            post_time = datetime.fromtimestamp(post.created_utc)\n",
    "            if post_time < time_threshold:\n",
    "                continue\n",
    "\n",
    "            # Clean and combine title and body text\n",
    "            full_text = clean_text(post.title + ' ' + post.selftext)\n",
    "\n",
    "            # Perform sentiment analysis using Grok API first\n",
    "            print(f\"Analyzing post: {post.title}\")\n",
    "            sentiment_data = get_grok_sentiment(full_text)\n",
    "            \n",
    "            # Get tickers from Grok analysis\n",
    "            grok_ticker = sentiment_data.get(\"ticker\")\n",
    "            \n",
    "            # Combine ticker sources, prioritizing Grok's analysis\n",
    "            tickers = set()\n",
    "            if grok_ticker and grok_ticker.upper() not in ['NULL', 'NONE', '']:\n",
    "                tickers.add(grok_ticker.upper())\n",
    "            \n",
    "            if not tickers:\n",
    "                continue\n",
    "            \n",
    "            compound_score = sentiment_data[\"compound\"]\n",
    "            confidence = sentiment_data.get(\"confidence\", 1.0)\n",
    "\n",
    "            # Weight the sentiment by confidence\n",
    "            weighted_score = compound_score * confidence\n",
    "\n",
    "            for ticker in tickers:\n",
    "                # Create new index\n",
    "                if ticker not in sentiment_scores:\n",
    "                    sentiment_scores[ticker] = []\n",
    "                    post_count[ticker] = 0\n",
    "                    ticker_posts[ticker] = []\n",
    "\n",
    "                # Add to ticker index\n",
    "                sentiment_scores[ticker].append(weighted_score)\n",
    "                post_count[ticker] += 1\n",
    "                ticker_posts[ticker].append({\n",
    "                    'title': post.title[:100],\n",
    "                    'sentiment': sentiment_data['sentiment'],\n",
    "                    'score': compound_score,\n",
    "                    'confidence': confidence,\n",
    "                    'ticker': ticker,\n",
    "                })\n",
    "\n",
    "            processed_posts += 1\n",
    "            \n",
    "            # Print progress\n",
    "            if processed_posts % 10 == 0:\n",
    "                print(f\"Processed {processed_posts} posts...\")\n",
    "\n",
    "            # Rate limiting\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing post: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Calculate average sentiment scores\n",
    "    avg_sentiment = {}\n",
    "\n",
    "    # Takes the average sentiment score for each ticker\n",
    "    for ticker in sentiment_scores:\n",
    "        scores = sentiment_scores[ticker]\n",
    "        avg_score = sum(scores) / len(scores)\n",
    "        avg_sentiment[ticker] = {\n",
    "            'score': avg_score,\n",
    "            'post_count': post_count[ticker],\n",
    "            'posts': ticker_posts[ticker]\n",
    "        }\n",
    "\n",
    "    return avg_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff43fbe-0e22-4cc0-bcdf-999357a1fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check stock prices\n",
    "def check_stock_price(ticker):\n",
    "    request_params = StockLatestQuoteRequest(symbol_or_symbols=ticker)\n",
    "    latest_symbol_quote = stock_quote_client.get_stock_latest_quote(request_params)\n",
    "    return latest_symbol_quote[ticker].ask_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e10a92d-0c2b-4ba3-bfdb-5077c3dc3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute trades based on sentiment\n",
    "def execute_trades_based_on_sentiment(sentiment_data, qty):\n",
    "    \"\"\"Submit buy/sell orders via Alpaca based on average sentiment scores\"\"\"\n",
    "    print(\"Executing trades based on sentiment...\")\n",
    "    \n",
    "    for ticker, data in sentiment_data.items():\n",
    "        avg_score = data['score']\n",
    "        print(f\"Evaluating {ticker}: avg_score = {avg_score}\")\n",
    "\n",
    "        # if abs(avg_score) > 0.49 and abs(avg_score) < 0.65:\n",
    "        #     qty = 300\n",
    "        try:\n",
    "            if avg_score < -0.49:\n",
    "                # Buy on strongly negative sentiment\n",
    "                buy_order_data = MarketOrderRequest(\n",
    "                    symbol=ticker,\n",
    "                    qty=qty,\n",
    "                    side=OrderSide.BUY,\n",
    "                    time_in_force=TimeInForce.DAY\n",
    "                )\n",
    "                buy_order = trading_client.submit_order(buy_order_data)\n",
    "                print(f\"Buy order submitted for {qty} shares of {ticker}: {buy_order.id}\")\n",
    "                \n",
    "            elif avg_score > 0.49:\n",
    "                # Check if we hold the position before selling\n",
    "                sell_order_data = MarketOrderRequest(\n",
    "                    symbol=\"AAPL\",\n",
    "                    qty=1,\n",
    "                    side=OrderSide.SELL,\n",
    "                    time_in_force=TimeInForce.DAY\n",
    "                )\n",
    "                sell_order = trading_client.submit_order(sell_order_data)\n",
    "                print(f\"Sell order submitted for {qty} shares of {ticker}: {sell_order.id}\")\n",
    "            else:\n",
    "                print(f\"No action for {ticker}: avg_score {avg_score} within neutral range\")\n",
    "            \n",
    "            # Rate limiting between orders\n",
    "            time.sleep(1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error executing trade for {ticker}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5c64eb3-35b0-459c-9234-fc6d21dea883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching sentiment from r/wallstreetbets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikey\\AppData\\Local\\Temp\\ipykernel_2424\\3489495118.py:13: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  time_threshold = datetime.utcnow() - timedelta(hours=hours)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing post: $APLD AI Hyperscaler deal imminent ⚠️\n",
      "\n",
      "Average Sentiment:\n",
      "APLD: score=0.77, posts=1\n",
      "Executing trades based on sentiment...\n",
      "Evaluating APLD: avg_score = 0.765\n",
      "Sell order submitted for 1 shares of APLD: 4df21a23-296d-47d0-88fe-d0f31f811cd4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #Get sentiment data (adjust params as needed)\n",
    "    sentiment = get_reddit_sentiment('wallstreetbets', 24, 10)\n",
    "    \n",
    "    # Print sentiment for reference\n",
    "    print(\"\\nAverage Sentiment:\")\n",
    "    for ticker, data in sentiment.items():\n",
    "        print(f\"{ticker}: score={data['score']:.2f}, posts={data['post_count']}\")\n",
    "    \n",
    "    # Execute trades\n",
    "    execute_trades_based_on_sentiment(sentiment, 1)  # Adjust qty as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d53f554-e35d-43a0-8fcc-43f04535c09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f18763-d933-4017-9341-b22a8f6c324f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
