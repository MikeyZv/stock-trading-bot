{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2550e01d-63bb-4264-ab2c-1ce76dd22704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\mikey\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import praw\n",
    "import alpaca_trade_api\n",
    "import pandas\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf811f-3453-47df-953b-e6c1d60dfff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=REDDIT_CLIENT_ID,\n",
    "    client_secret=REDDIT_CLIENT_SECRET,\n",
    "    user_agent=REDDIT_USER_AGENT\n",
    ")\n",
    "\n",
    "# Initialize Alpaca API\n",
    "alpaca = alpaca_trade_api.REST(ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_BASE_URL, api_version='v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95550b97-42d0-425a-9819-616e287c1258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text for sentiment analysis\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e00f416-7041-482e-bcc3-27e2429f6412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment from r/WallStreetBets\n",
    "def get_reddit_sentiment():\n",
    "    subreddit = reddit.subreddit('wallstreetbets')\n",
    "    posts = subreddit.hot(limit=100)\n",
    "    sentiment_scores = {}\n",
    "    post_count = {}\n",
    "\n",
    "    # Time filter: only posts from the last `hours`\n",
    "    time_threshold = datetime.utcnow() - timedelta(hours=24)\n",
    "\n",
    "    for post in posts:\n",
    "        post_time = datetime.fromtimestamp(post.created_utc)\n",
    "        if post_time < time_threshold:\n",
    "            continue\n",
    "\n",
    "        # Extract stock tickers (simple regex for uppercase words, e.g., TSLA, GME)\n",
    "        # print(\"not clean\")\n",
    "        # print(post.title + \" | \" + post.selftext)\n",
    "        text = clean_text(post.title + ' ' + post.selftext)\n",
    "        # print(\"clean text\")\n",
    "        # print(text)\n",
    "        tickers = set(ticker.upper() for ticker in re.findall(r'(?:\\$)?\\b(?!YOLO\\b)[A-Z]{2,5}\\b', text)) # Match 2-5 letter tickers\n",
    "\n",
    "        # Perform sentiment analysis\n",
    "        analyzer = SentimentIntensityAnalyzer()\n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound_score = sentiment['compound']\n",
    "\n",
    "        for ticker in tickers:\n",
    "            if ticker not in sentiment_scores:\n",
    "                sentiment_scores[ticker] = 0\n",
    "                post_count[ticker] = 0\n",
    "            sentiment_scores[ticker] += compound_score\n",
    "            post_count[ticker] += 1\n",
    "\n",
    "    # Average sentiment scores\n",
    "    avg_sentiment = {ticker: sentiment_scores[ticker] / post_count[ticker] for ticker in sentiment_scores if post_count[ticker] > 0}\n",
    "    return avg_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5c64eb3-35b0-459c-9234-fc6d21dea883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikey\\AppData\\Local\\Temp\\ipykernel_16756\\4175791414.py:9: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  time_threshold = datetime.utcnow() - timedelta(hours=24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SPY': 0.9625,\n",
       " '$OPEN': 0.2732,\n",
       " 'HIMS': 0.0,\n",
       " '$SBET': 0.4278,\n",
       " 'SPX': 0.3119,\n",
       " '$AEO': 0.9859,\n",
       " '$GAP': 0.9859,\n",
       " 'AEO': 0.9859,\n",
       " 'FMCC': 0.4404,\n",
       " 'LULU': 0.0,\n",
       " 'VSTM': 0.5223,\n",
       " 'IPO': 0.3612,\n",
       " 'FIG': 0.3612,\n",
       " '$WEN': 0.7213}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beans = get_reddit_sentiment()\n",
    "# for ticker, score in beans.items():\n",
    "#     print(ticker + ' ' + str(score))\n",
    "get_reddit_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cea104-f513-4cd9-9bf4-00c6c8dc7a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
